#!/usr/bin/env python3
"""
Advanced RAG Engine Demo Runner

This script demonstrates the key capabilities of the Advanced Hybrid RAG Engine.
Perfect for showcasing to recruiters or during interviews.

Features demonstrated:
- Multi-modal LLM integration  
- Real-time streaming responses
- Performance analytics
- Evaluation metrics
- Production API capabilities
"""

import asyncio
import json
import time
import subprocess
import sys
from pathlib import Path
from typing import List, Dict

# Add src to path
sys.path.append(str(Path(__file__).parent / "src"))

from advanced_ask import AdvancedHybridRAG, QueryRequest
from evaluation import RAGEvaluator, TestCase, SAMPLE_TEST_CASES

class RAGDemo:
    """Demo orchestrator for the Advanced RAG Engine"""
    
    def __init__(self):
        self.rag_engine = AdvancedHybridRAG()
        self.evaluator = RAGEvaluator()
        
    async def initialize(self):
        """Initialize all components"""
        print("üöÄ Initializing Advanced Hybrid RAG Engine...")
        await self.rag_engine.initialize()
        print("‚úÖ RAG Engine ready!")
        
    async def demo_basic_capabilities(self):
        """Demonstrate basic RAG capabilities"""
        print("\n" + "="*60)
        print("üß† DEMO 1: Basic RAG Capabilities")
        print("="*60)
        
        questions = [
            "What are the main compliance requirements?",
            "How do I submit a thesis proposal?",
            "What are the Thor project specifications?"
        ]
        
        for i, question in enumerate(questions, 1):
            print(f"\nüìù Question {i}: {question}")
            print("-" * 50)
            
            request = QueryRequest(
                question=question,
                llm_provider="ollama",
                model="llama3",
                enable_reranking=True
            )
            
            start_time = time.time()
            response = await self.rag_engine.query(request)
            processing_time = time.time() - start_time
            
            print(f"ü§ñ Answer: {response.answer[:200]}...")
            print(f"üìö Citations: {len(response.citations)} sources")
            print(f"‚ö° Processing Time: {processing_time:.2f}s")
            print(f"üîß Chunks Used: {response.metadata['chunks_used']}")
    
    async def demo_advanced_features(self):
        """Demonstrate advanced features"""
        print("\n" + "="*60)
        print("üéØ DEMO 2: Advanced RAG Features")
        print("="*60)
        
        question = "What are the compliance requirements for documentation?"
        
        # Test different configurations
        configs = [
            {"name": "Basic", "reranking": False, "expansion": False},
            {"name": "With Reranking", "reranking": True, "expansion": False},
            {"name": "With Query Expansion", "reranking": False, "expansion": True},
            {"name": "Full Advanced", "reranking": True, "expansion": True}
        ]
        
        results = []
        
        for config in configs:
            print(f"\nüîß Testing: {config['name']}")
            print("-" * 30)
            
            request = QueryRequest(
                question=question,
                llm_provider="ollama",
                enable_reranking=config["reranking"],
                enable_query_expansion=config["expansion"]
            )
            
            start_time = time.time()
            response = await self.rag_engine.query(request)
            processing_time = time.time() - start_time
            
            results.append({
                "config": config["name"],
                "processing_time": processing_time,
                "chunks_used": response.metadata['chunks_used'],
                "answer_length": len(response.answer)
            })
            
            print(f"‚ö° Time: {processing_time:.2f}s")
            print(f"üìä Chunks: {response.metadata['chunks_used']}")
            print(f"üìù Answer Length: {len(response.answer)} chars")
        
        # Compare results
        print("\nüìä PERFORMANCE COMPARISON:")
        print("-" * 40)
        for result in results:
            print(f"{result['config']:<20} | {result['processing_time']:.2f}s | {result['chunks_used']} chunks")
    
    async def demo_evaluation_framework(self):
        """Demonstrate evaluation capabilities"""
        print("\n" + "="*60)
        print("üß™ DEMO 3: Evaluation Framework")
        print("="*60)
        
        print("Running comprehensive evaluation on test cases...")
        
        # Initialize evaluator
        await self.evaluator.initialize()
        
        # Run evaluation on sample test cases
        results = await self.evaluator.run_evaluation(
            SAMPLE_TEST_CASES[:2],  # Use first 2 test cases for demo
            output_file="demo_evaluation_results.json"
        )
        
        # Display key metrics
        overall = results["aggregate_metrics"]["overall_performance"]
        
        print("\nüìà EVALUATION RESULTS:")
        print("-" * 30)
        print(f"üéØ Avg Relevance Score: {overall['avg_relevance_score']:.3f}")
        print(f"üß† Semantic Similarity: {overall['avg_semantic_similarity']:.3f}")
        print(f"üìö Citation Accuracy: {overall['avg_citation_accuracy']:.3f}")
        print(f"‚ö° Avg Processing Time: {overall['avg_processing_time']:.2f}s")
        print(f"üîç Context Precision: {overall['avg_context_precision']:.3f}")
        print(f"üé™ Context Recall: {overall['avg_context_recall']:.3f}")
        
        # Generate report
        report_file = self.evaluator.generate_report(
            "demo_evaluation_results.json",
            "demo_evaluation_report"
        )
        print(f"\nüìä Detailed report: {report_file}")
    
    async def demo_streaming_capabilities(self):
        """Demonstrate streaming response capabilities"""  
        print("\n" + "="*60)
        print("üì° DEMO 4: Streaming Responses")
        print("="*60)
        
        question = "Explain the thesis submission process step by step."
        print(f"üìù Question: {question}")
        print("\nü§ñ Streaming Response:")
        print("-" * 30)
        
        request = QueryRequest(
            question=question,
            use_streaming=True,
            llm_provider="ollama"
        )
        
        print("üîÑ Starting stream...")
        async for chunk in self.rag_engine.stream_query(request):
            # Parse the streaming data
            if chunk.startswith("data: "):
                try:
                    data = json.loads(chunk[6:])
                    if data["type"] == "content":
                        print(data["content"], end=" ", flush=True)
                    elif data["type"] == "end":
                        print(f"\n\n‚úÖ Stream completed in {data['processing_time']:.2f}s")
                except:
                    pass
    
    def demo_api_capabilities(self):
        """Demonstrate API server capabilities"""
        print("\n" + "="*60)
        print("üåê DEMO 5: Production API Server")
        print("="*60)
        
        print("üì° API Server Features:")
        print("‚Ä¢ RESTful API with FastAPI")
        print("‚Ä¢ Automatic OpenAPI documentation")
        print("‚Ä¢ Health monitoring endpoints")
        print("‚Ä¢ Real-time analytics")
        print("‚Ä¢ Response caching")
        print("‚Ä¢ Multi-LLM support")
        
        print("\nüöÄ To start the API server:")
        print("   python src/advanced_ask.py --server")
        print("   API: http://localhost:8000")
        print("   Docs: http://localhost:8000/docs")
        
        print("\nüé® To start the Streamlit UI:")
        print("   streamlit run src/streamlit_app.py")
        print("   UI: http://localhost:8501")
        
        # Check if Qdrant is running
        try:
            import requests
            response = requests.get("http://localhost:6333", timeout=2)
            print("\n‚úÖ Qdrant is running (required for demos)")
        except:
            print("\n‚ö†Ô∏è  Qdrant not detected. Run: docker compose up -d")
    
    def show_project_highlights(self):
        """Show key project highlights for recruiters"""
        print("\n" + "="*60)
        print("üèÜ PROJECT HIGHLIGHTS FOR GENAI ROLES")
        print("="*60)
        
        highlights = [
            "üß† Advanced RAG Architecture",
            "   ‚Ä¢ Hybrid retrieval (semantic + keyword)",
            "   ‚Ä¢ Cross-encoder reranking",
            "   ‚Ä¢ Query expansion techniques",
            "   ‚Ä¢ Multi-LLM integration",
            "",
            "üöÄ Production Engineering",
            "   ‚Ä¢ FastAPI with async operations",
            "   ‚Ä¢ Real-time streaming responses",
            "   ‚Ä¢ Response caching & optimization",
            "   ‚Ä¢ Health monitoring & analytics",
            "",
            "üß™ ML Engineering & Evaluation",
            "   ‚Ä¢ Comprehensive evaluation framework",
            "   ‚Ä¢ Automated testing with metrics",
            "   ‚Ä¢ Performance benchmarking",
            "   ‚Ä¢ A/B testing capabilities",
            "",
            "üé® Full-Stack AI Development", 
            "   ‚Ä¢ Backend API development",
            "   ‚Ä¢ Frontend UI (Streamlit)",
            "   ‚Ä¢ Database integration (Qdrant)",
            "   ‚Ä¢ Analytics dashboards",
            "",
            "üìä Modern AI Practices",
            "   ‚Ä¢ Pydantic for data validation",
            "   ‚Ä¢ Structured JSON responses",
            "   ‚Ä¢ Error handling & logging",
            "   ‚Ä¢ Configuration management"
        ]
        
        for highlight in highlights:
            print(highlight)
    
    async def run_full_demo(self):
        """Run the complete demo sequence"""
        print("üéØ ADVANCED HYBRID RAG ENGINE - COMPREHENSIVE DEMO")
        print("=" * 60)
        print("Showcasing production-ready GenAI engineering capabilities")
        
        await self.initialize()
        
        # Run all demos
        await self.demo_basic_capabilities()
        await self.demo_advanced_features()
        await self.demo_evaluation_framework()
        await self.demo_streaming_capabilities()
        self.demo_api_capabilities()
        self.show_project_highlights()
        
        print("\nüéâ Demo complete!")
        print("üíº This project demonstrates modern GenAI engineering including:")
        print("   ‚Ä¢ Advanced RAG techniques")
        print("   ‚Ä¢ Production API development")  
        print("   ‚Ä¢ ML evaluation frameworks")
        print("   ‚Ä¢ Real-time streaming systems")
        print("   ‚Ä¢ Full-stack AI applications")

async def main():
    """Main demo runner"""
    demo = RAGDemo()
    await demo.run_full_demo()

if __name__ == "__main__":
    asyncio.run(main())